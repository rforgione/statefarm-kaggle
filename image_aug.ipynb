{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 90.0% of memory, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import (Dense, BatchNormalization, Convolution2D, \n",
    "                         MaxPooling2D, Dropout, Input, Flatten)\n",
    "from keras.optimizers import Adam\n",
    "from keras_utilities import Vgg16, get_batches, onehot\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = \"sample/\"\n",
    "# path = \"data/\"\n",
    "path = \"microsample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2057 images belonging to 10 classes.\n",
      "Found 1983 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "trn_batches = get_batches(path+\"train\")\n",
    "val_batches = get_batches(path+\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_labels = onehot(trn_batches.classes)\n",
    "val_labels = onehot(val_batches.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune the vgg model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.ft(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a baseline model to see what happens without any data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2057/2057 [==============================] - 94s - loss: 3.3335 - acc: 0.2912 - val_loss: 2.9975 - val_acc: 0.3469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60b5788690>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.model.fit_generator(generator=trn_batches, samples_per_epoch=trn_batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any augmentation, we get a val loss of 2.9975."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZCA Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2057 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "   4/2057 [..............................] - ETA: 93s - loss: 1.7248 - acc: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.py:482: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn'tbeen fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 94s - loss: 3.4494 - acc: 0.2820 - val_loss: 2.1387 - val_acc: 0.3853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60a2aa1bd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(zca_whitening=True)\n",
    "trn_batches = get_batches(path+\"train\", gen=gen)\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.model.fit_generator(generator=trn_batches, samples_per_epoch=trn_batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substantial improvement to 2.1387."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: use ZCA whitening**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2057 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "2057/2057 [==============================] - 94s - loss: 3.2577 - acc: 0.3009 - val_loss: 2.9101 - val_acc: 0.3278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60912b2150>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rotation_range=.1)\n",
    "trn_batches = get_batches(path+\"train\", gen=gen)\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.model.fit_generator(generator=trn_batches, samples_per_epoch=trn_batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helped a little, not much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2057 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "2057/2057 [==============================] - 94s - loss: 3.4038 - acc: 0.2839 - val_loss: 2.1824 - val_acc: 0.4433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f608dff60d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rotation_range=.2)\n",
    "trn_batches = get_batches(path+\"train\", gen=gen)\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.model.fit_generator(generator=trn_batches, samples_per_epoch=trn_batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Solid val loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2057 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "2057/2057 [==============================] - 94s - loss: 3.2890 - acc: 0.3004 - val_loss: 3.0651 - val_acc: 0.3495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f608ad71290>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rotation_range=.2)\n",
    "trn_batches = get_batches(path+\"train\", gen=gen)\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.model.fit_generator(generator=trn_batches, samples_per_epoch=trn_batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: rotation range of 0.2. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width Shift Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2057 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "2057/2057 [==============================] - 94s - loss: 3.4075 - acc: 0.2708 - val_loss: 2.7971 - val_acc: 0.3298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f607d08bb10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(width_shift_range=.1)\n",
    "trn_batches = get_batches(path+\"train\", gen=gen)\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.model.fit_generator(generator=trn_batches, samples_per_epoch=trn_batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Better than without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2057 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "2057/2057 [==============================] - 94s - loss: 3.6077 - acc: 0.2280 - val_loss: 2.0524 - val_acc: 0.4175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f607857f290>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(width_shift_range=.2)\n",
    "trn_batches = get_batches(path+\"train\", gen=gen)\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.model.fit_generator(generator=trn_batches, samples_per_epoch=trn_batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHOA big improvement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2057 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "2057/2057 [==============================] - 94s - loss: 3.5783 - acc: 0.2436 - val_loss: 2.5521 - val_acc: 0.3807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60751bed50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(width_shift_range=.3)\n",
    "trn_batches = get_batches(path+\"train\", gen=gen)\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.model.fit_generator(generator=trn_batches, samples_per_epoch=trn_batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Conclusion: 0.2 width shift range. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Height Shift Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2057 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "2057/2057 [==============================] - 94s - loss: 3.4127 - acc: 0.2640 - val_loss: 2.6254 - val_acc: 0.2925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60726ba190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(height_shift_range=.1)\n",
    "trn_batches = get_batches(path+\"train\", gen=gen)\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.model.fit_generator(generator=trn_batches, samples_per_epoch=trn_batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2057 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "2057/2057 [==============================] - 94s - loss: 3.4198 - acc: 0.2533 - val_loss: 2.6658 - val_acc: 0.3676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f606f2ac190>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(height_shift_range=.2)\n",
    "trn_batches = get_batches(path+\"train\", gen=gen)\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.model.fit_generator(generator=trn_batches, samples_per_epoch=trn_batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2057 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "2057/2057 [==============================] - 94s - loss: 3.4300 - acc: 0.2640 - val_loss: 2.4316 - val_acc: 0.3585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f606bd688d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(height_shift_range=.3)\n",
    "trn_batches = get_batches(path+\"train\", gen=gen)\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.model.fit_generator(generator=trn_batches, samples_per_epoch=trn_batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
