{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import (Dense, BatchNormalization, Convolution2D, \n",
    "                         MaxPooling2D, Dropout, Input, Flatten)\n",
    "from keras.optimizers import Adam\n",
    "from keras_utilities import Vgg16, get_batches, onehot, load_array, save_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_conv_layer = [i for i,l in enumerate(mod.model.layers) if isinstance(l, Convolution2D)][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20441 images belonging to 10 classes.\n",
      "Found 1983 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "trn_batches = get_batches(\"data/train\", shuffle=False, batch_size=64)\n",
    "val_batches = get_batches(\"data/valid\", shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_mod = Model(input=mod.model.input, output=mod.model.layers[max_conv_layer].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_features = conv_mod.predict_generator(trn_batches, trn_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20441, 512, 14, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(\"conv_features.dat\", conv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_features = load_array(\"conv_features.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20441, 512, 14, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_val_features = conv_mod.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_array(\"conv_val_features.dat\", conv_val_features)\n",
    "conv_val_features = load_array(\"conv_val_features.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_labels = onehot(trn_batches.classes)\n",
    "val_labels = onehot(val_batches.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20441 images belonging to 10 classes.\n",
      "Found 1983 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20441, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = .8\n",
    "inp = Input(shape=conv_mod.layers[-1].output_shape[1:])\n",
    "mp = MaxPooling2D((2,2))(inp)\n",
    "ft = Flatten()(mp)\n",
    "dr1 = Dropout(p/2)(ft)\n",
    "dn1 = Dense(128, activation='relu')(dr1)\n",
    "bn1 = BatchNormalization()(dn1)\n",
    "dr2 = Dropout(p/2)(bn1)\n",
    "dn2 = Dense(128, activation='relu')(dr2)\n",
    "bn2 = BatchNormalization()(dn2)\n",
    "dr3 = Dropout(p)(bn2)\n",
    "dn3 = Dense(10, activation='softmax')(dr3)\n",
    "\n",
    "dense_mod = Model(input=inp, output=dn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=.001)\n",
    "dense_mod.compile(optimizer=opt, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20441 samples, validate on 1983 samples\n",
      "Epoch 1/10\n",
      "20441/20441 [==============================] - 6s - loss: 1.4803 - val_loss: 1.1191\n",
      "Epoch 2/10\n",
      "20441/20441 [==============================] - 6s - loss: 0.2737 - val_loss: 1.3544\n",
      "Epoch 3/10\n",
      "20441/20441 [==============================] - 6s - loss: 0.1315 - val_loss: 1.0569\n",
      "Epoch 4/10\n",
      "20441/20441 [==============================] - 6s - loss: 0.0948 - val_loss: 1.2024\n",
      "Epoch 5/10\n",
      "20441/20441 [==============================] - 6s - loss: 0.0624 - val_loss: 2.0449\n",
      "Epoch 6/10\n",
      "20441/20441 [==============================] - 6s - loss: 0.0541 - val_loss: 1.6194\n",
      "Epoch 7/10\n",
      "20441/20441 [==============================] - 6s - loss: 0.0466 - val_loss: 1.7684\n",
      "Epoch 8/10\n",
      "20441/20441 [==============================] - 6s - loss: 0.0407 - val_loss: 1.5232\n",
      "Epoch 9/10\n",
      "20441/20441 [==============================] - 6s - loss: 0.0421 - val_loss: 2.3329\n",
      "Epoch 10/10\n",
      "20441/20441 [==============================] - 6s - loss: 0.0335 - val_loss: 2.0566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa247836cd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_mod.fit(conv_features, \n",
    "              trn_labels, \n",
    "              batch_size=64, \n",
    "              nb_epoch=10, \n",
    "              validation_data=(conv_val_features, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is an experiment to see if I get similar results to Jeremy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model=vgg.model\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat = conv_model.predict_generator(trn_batches, trn_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_conv_feat = conv_model.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(\"jeremy_conv_feat.dat\", conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(\"jeremy_val_conv_feat.dat\", val_conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat = load_array(\"jeremy_conv_feat.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_conv_feat = load_array(\"jeremy_val_conv_feat.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = .8\n",
    "inp = Input(shape=conv_model.layers[-1].output_shape[1:])\n",
    "mp = MaxPooling2D((2,2))(inp)\n",
    "ft = Flatten()(mp)\n",
    "dr1 = Dropout(p)(ft)\n",
    "dn1 = Dense(128, activation='relu')(dr1)\n",
    "bn1 = BatchNormalization()(dn1)\n",
    "dr2 = Dropout(p)(bn1)\n",
    "dn2 = Dense(128, activation='relu')(dr2)\n",
    "bn2 = BatchNormalization()(dn2)\n",
    "dr3 = Dropout(p)(bn2)\n",
    "dn3 = Dense(10, activation='softmax')(dr3)\n",
    "\n",
    "dense_mod = Model(input=inp, output=dn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.00001)\n",
    "dense_mod.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20441 samples, validate on 1983 samples\n",
      "Epoch 1/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.2155 - acc: 0.9342 - val_loss: 1.1332 - val_acc: 0.6722\n",
      "Epoch 2/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.2100 - acc: 0.9341 - val_loss: 1.1204 - val_acc: 0.6737\n",
      "Epoch 3/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.2111 - acc: 0.9355 - val_loss: 1.0957 - val_acc: 0.6858\n",
      "Epoch 4/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.2058 - acc: 0.9368 - val_loss: 1.1042 - val_acc: 0.6808\n",
      "Epoch 5/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.2088 - acc: 0.9349 - val_loss: 1.1040 - val_acc: 0.6813\n",
      "Epoch 6/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.2039 - acc: 0.9358 - val_loss: 1.1077 - val_acc: 0.6823\n",
      "Epoch 7/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.2024 - acc: 0.9374 - val_loss: 1.1002 - val_acc: 0.6838\n",
      "Epoch 8/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.2039 - acc: 0.9380 - val_loss: 1.0855 - val_acc: 0.6878\n",
      "Epoch 9/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.2025 - acc: 0.9363 - val_loss: 1.0961 - val_acc: 0.6843\n",
      "Epoch 10/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.1959 - acc: 0.9391 - val_loss: 1.0929 - val_acc: 0.6843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fabcdceb5d0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_mod.fit(conv_feat, trn_labels, batch_size=64, nb_epoch=10, validation_data=(val_conv_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001)\n",
    "dense_mod.compile(optimizer=opt, loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20441 samples, validate on 1983 samples\n",
      "Epoch 1/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.1692 - val_loss: 1.3608\n",
      "Epoch 2/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.1520 - val_loss: 1.3010\n",
      "Epoch 3/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.1378 - val_loss: 1.3464\n",
      "Epoch 4/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.1297 - val_loss: 1.3224\n",
      "Epoch 5/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.1351 - val_loss: 1.3344\n",
      "Epoch 6/10\n",
      "20441/20441 [==============================] - 4s - loss: 0.1237 - val_loss: 1.3231\n",
      "Epoch 7/10\n",
      "12608/20441 [=================>............] - ETA: 1s - loss: 0.1143"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1f54c5b72ffc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdense_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_conv_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    878\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m                         \u001b[0;31m# do not slice the training phase flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mslice_X\u001b[0;34m(X, start, stop)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dense_mod.fit(conv_feat, trn_labels, batch_size=64, validation_data=(val_conv_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
