{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 75.0% of memory, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_utilities import *\n",
    "from keras_utilities.models.vgg16bn import Vgg16BN\n",
    "from keras_utilities.models.vgg16 import Vgg16\n",
    "from keras.layers import Dense, Merge\n",
    "import os\n",
    "from numpy import array\n",
    "from IPython.display import FileLink\n",
    "from numpy.random import permutation\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import AveragePooling2D, Input, Dense, Flatten\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras_utilities import Vgg16, save_array, load_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod = True\n",
    "\n",
    "path = 'data/'\n",
    "    \n",
    "batch_size = 64\n",
    "\n",
    "model_dir = \"models/\"\n",
    "results_dir = \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20441 images belonging to 10 classes.\n",
      "Found 1983 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "#     samplewise_std_normalization=True,\n",
    "    zca_whitening=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.2,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "batches = get_batches(path+\"train\", batch_size=128, shuffle=False)\n",
    "val_batches = get_batches(path+\"valid\", batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune_resnet(nb_classes, lr=.001):\n",
    "    rn = ResNet50()\n",
    "    \n",
    "    x = rn.layers[-4].output \n",
    "    mod = AveragePooling2D(name='avg_pool_ft', pool_size=(7,7))(x)\n",
    "    mod = Flatten(name='flatten_ft')(mod)\n",
    "    mod = Dense(nb_classes, name='dense_ft', activation='softmax')(mod)\n",
    "    \n",
    "    newmod = Model(input=rn.input, output=mod)\n",
    "    \n",
    "    for i in newmod.layers:\n",
    "        if i.name in ['dense_ft']:\n",
    "            i.trainable = True\n",
    "        else:\n",
    "            i.trainable = False\n",
    "    \n",
    "    opt = Adam(lr=lr)\n",
    "    newmod.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "    return newmod\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ft = finetune_resnet(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input_33', False)\n",
      "('zeropadding2d_13', False)\n",
      "('conv1', False)\n",
      "('bn_conv1', False)\n",
      "('activation_589', False)\n",
      "('maxpooling2d_13', False)\n",
      "('res2a_branch2a', False)\n",
      "('bn2a_branch2a', False)\n",
      "('activation_590', False)\n",
      "('res2a_branch2b', False)\n",
      "('bn2a_branch2b', False)\n",
      "('activation_591', False)\n",
      "('res2a_branch2c', False)\n",
      "('res2a_branch1', False)\n",
      "('bn2a_branch2c', False)\n",
      "('bn2a_branch1', False)\n",
      "('merge_193', False)\n",
      "('activation_592', False)\n",
      "('res2b_branch2a', False)\n",
      "('bn2b_branch2a', False)\n",
      "('activation_593', False)\n",
      "('res2b_branch2b', False)\n",
      "('bn2b_branch2b', False)\n",
      "('activation_594', False)\n",
      "('res2b_branch2c', False)\n",
      "('bn2b_branch2c', False)\n",
      "('merge_194', False)\n",
      "('activation_595', False)\n",
      "('res2c_branch2a', False)\n",
      "('bn2c_branch2a', False)\n",
      "('activation_596', False)\n",
      "('res2c_branch2b', False)\n",
      "('bn2c_branch2b', False)\n",
      "('activation_597', False)\n",
      "('res2c_branch2c', False)\n",
      "('bn2c_branch2c', False)\n",
      "('merge_195', False)\n",
      "('activation_598', False)\n",
      "('res3a_branch2a', False)\n",
      "('bn3a_branch2a', False)\n",
      "('activation_599', False)\n",
      "('res3a_branch2b', False)\n",
      "('bn3a_branch2b', False)\n",
      "('activation_600', False)\n",
      "('res3a_branch2c', False)\n",
      "('res3a_branch1', False)\n",
      "('bn3a_branch2c', False)\n",
      "('bn3a_branch1', False)\n",
      "('merge_196', False)\n",
      "('activation_601', False)\n",
      "('res3b_branch2a', False)\n",
      "('bn3b_branch2a', False)\n",
      "('activation_602', False)\n",
      "('res3b_branch2b', False)\n",
      "('bn3b_branch2b', False)\n",
      "('activation_603', False)\n",
      "('res3b_branch2c', False)\n",
      "('bn3b_branch2c', False)\n",
      "('merge_197', False)\n",
      "('activation_604', False)\n",
      "('res3c_branch2a', False)\n",
      "('bn3c_branch2a', False)\n",
      "('activation_605', False)\n",
      "('res3c_branch2b', False)\n",
      "('bn3c_branch2b', False)\n",
      "('activation_606', False)\n",
      "('res3c_branch2c', False)\n",
      "('bn3c_branch2c', False)\n",
      "('merge_198', False)\n",
      "('activation_607', False)\n",
      "('res3d_branch2a', False)\n",
      "('bn3d_branch2a', False)\n",
      "('activation_608', False)\n",
      "('res3d_branch2b', False)\n",
      "('bn3d_branch2b', False)\n",
      "('activation_609', False)\n",
      "('res3d_branch2c', False)\n",
      "('bn3d_branch2c', False)\n",
      "('merge_199', False)\n",
      "('activation_610', False)\n",
      "('res4a_branch2a', False)\n",
      "('bn4a_branch2a', False)\n",
      "('activation_611', False)\n",
      "('res4a_branch2b', False)\n",
      "('bn4a_branch2b', False)\n",
      "('activation_612', False)\n",
      "('res4a_branch2c', False)\n",
      "('res4a_branch1', False)\n",
      "('bn4a_branch2c', False)\n",
      "('bn4a_branch1', False)\n",
      "('merge_200', False)\n",
      "('activation_613', False)\n",
      "('res4b_branch2a', False)\n",
      "('bn4b_branch2a', False)\n",
      "('activation_614', False)\n",
      "('res4b_branch2b', False)\n",
      "('bn4b_branch2b', False)\n",
      "('activation_615', False)\n",
      "('res4b_branch2c', False)\n",
      "('bn4b_branch2c', False)\n",
      "('merge_201', False)\n",
      "('activation_616', False)\n",
      "('res4c_branch2a', False)\n",
      "('bn4c_branch2a', False)\n",
      "('activation_617', False)\n",
      "('res4c_branch2b', False)\n",
      "('bn4c_branch2b', False)\n",
      "('activation_618', False)\n",
      "('res4c_branch2c', False)\n",
      "('bn4c_branch2c', False)\n",
      "('merge_202', False)\n",
      "('activation_619', False)\n",
      "('res4d_branch2a', False)\n",
      "('bn4d_branch2a', False)\n",
      "('activation_620', False)\n",
      "('res4d_branch2b', False)\n",
      "('bn4d_branch2b', False)\n",
      "('activation_621', False)\n",
      "('res4d_branch2c', False)\n",
      "('bn4d_branch2c', False)\n",
      "('merge_203', False)\n",
      "('activation_622', False)\n",
      "('res4e_branch2a', False)\n",
      "('bn4e_branch2a', False)\n",
      "('activation_623', False)\n",
      "('res4e_branch2b', False)\n",
      "('bn4e_branch2b', False)\n",
      "('activation_624', False)\n",
      "('res4e_branch2c', False)\n",
      "('bn4e_branch2c', False)\n",
      "('merge_204', False)\n",
      "('activation_625', False)\n",
      "('res4f_branch2a', False)\n",
      "('bn4f_branch2a', False)\n",
      "('activation_626', False)\n",
      "('res4f_branch2b', False)\n",
      "('bn4f_branch2b', False)\n",
      "('activation_627', False)\n",
      "('res4f_branch2c', False)\n",
      "('bn4f_branch2c', False)\n",
      "('merge_205', False)\n",
      "('activation_628', False)\n",
      "('res5a_branch2a', False)\n",
      "('bn5a_branch2a', False)\n",
      "('activation_629', False)\n",
      "('res5a_branch2b', False)\n",
      "('bn5a_branch2b', False)\n",
      "('activation_630', False)\n",
      "('res5a_branch2c', False)\n",
      "('res5a_branch1', False)\n",
      "('bn5a_branch2c', False)\n",
      "('bn5a_branch1', False)\n",
      "('merge_206', False)\n",
      "('activation_631', False)\n",
      "('res5b_branch2a', False)\n",
      "('bn5b_branch2a', False)\n",
      "('activation_632', False)\n",
      "('res5b_branch2b', False)\n",
      "('bn5b_branch2b', False)\n",
      "('activation_633', False)\n",
      "('res5b_branch2c', False)\n",
      "('bn5b_branch2c', False)\n",
      "('merge_207', False)\n",
      "('activation_634', False)\n",
      "('res5c_branch2a', False)\n",
      "('bn5c_branch2a', False)\n",
      "('activation_635', False)\n",
      "('res5c_branch2b', False)\n",
      "('bn5c_branch2b', False)\n",
      "('activation_636', False)\n",
      "('res5c_branch2c', False)\n",
      "('bn5c_branch2c', False)\n",
      "('merge_208', False)\n",
      "('activation_637', False)\n",
      "('avg_pool_ft', False)\n",
      "('flatten_ft', False)\n",
      "('dense_ft', True)\n"
     ]
    }
   ],
   "source": [
    "for i in res_ft.layers:\n",
    "    print (i.name, i.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20441/20441 [==============================] - 282s - loss: 1.0949 - acc: 0.7232 - val_loss: 1.4893 - val_acc: 0.4665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0bea75f510>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ft.fit_generator(batches, \n",
    "                     batches.nb_sample, \n",
    "                     validation_data=val_batches, \n",
    "                     nb_val_samples = val_batches.nb_sample, \n",
    "                     nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ft.save_weights(model_dir+\"resnet_1epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20441/20441 [==============================] - 273s - loss: 0.3029 - acc: 0.9444 - val_loss: 1.3098 - val_acc: 0.5774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef49c378d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ft.fit_generator(batches, \n",
    "                     batches.nb_sample, \n",
    "                     validation_data=val_batches, \n",
    "                     nb_val_samples = val_batches.nb_sample, \n",
    "                     nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ft.save_weights(model_dir+\"resnet_2epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20441/20441 [==============================] - 274s - loss: 0.1928 - acc: 0.9669 - val_loss: 1.5236 - val_acc: 0.5204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef5a91ae90>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ft.fit_generator(batches, \n",
    "                     batches.nb_sample, \n",
    "                     validation_data=val_batches, \n",
    "                     nb_val_samples = val_batches.nb_sample, \n",
    "                     nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f0c0194a9d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ft.save_weights(model_dir+\"resnet_3epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_prediction_file(filename, preds=None, model=None):\n",
    "    if not preds:\n",
    "        num_test_files = len(os.listdir(\"data/test/unknown\"))\n",
    "        test_gen = get_batches(\"data/test\", batch_size=128, shuffle=False)\n",
    "        preds = model.predict_generator(test_gen, val_samples=num_test_files)\n",
    "    elif not model and not preds:\n",
    "        raise ValueError(\"Must pass either preds or a model.\")\n",
    "        \n",
    "    files = os.listdir(\"data/test/unknown/\")\n",
    "        \n",
    "    pred_str = map(lambda x: \",\".join([\"%.10f\" % i for i in x]), preds.tolist())\n",
    "    rows = [\",\".join([a,b]) + \"\\n\" for a,b in zip(files, pred_str)]\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(\"img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n\")\n",
    "        for row in rows:\n",
    "            f.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_test_files = len(os.listdir(\"data/test/unknown\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = get_batches(\"data/test\", shuffle=False, class_mode=None)\n",
    "# preds = res_ft.predict_generator(test_gen, val_samples=num_test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(\"data/test/unknown/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img_81601.jpg',\n",
       " 'img_14887.jpg',\n",
       " 'img_62885.jpg',\n",
       " 'img_45125.jpg',\n",
       " 'img_22633.jpg',\n",
       " 'img_45660.jpg',\n",
       " 'img_88962.jpg',\n",
       " 'img_92987.jpg',\n",
       " 'img_26932.jpg',\n",
       " 'img_57972.jpg']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"results/resnet_3layer_ft.csv\"\n",
    "pred_str = map(lambda x: \",\".join([\"%.10f\" % i for i in x]), preds.tolist())\n",
    "rows = [\",\".join([a,b]) + \"\\n\" for a,b in zip(files, pred_str)]\n",
    "with open(filename, \"a\") as f:\n",
    "    f.write(\"img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n\")\n",
    "    for row in rows:\n",
    "        f.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='results/resnet_3layer_ft.csv' target='_blank'>results/resnet_3layer_ft.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/statefarm-kaggle/results/resnet_3layer_ft.csv"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(\"results/resnet_3layer_ft.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "17456/17456 [==============================] - 550s - loss: 1.8595 - acc: 0.4785 - val_loss: 1.5956 - val_acc: 0.5076\n"
     ]
    }
   ],
   "source": [
    "# as a comparison, let's see what the vgg model spits out for val loss\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.fit(batches, val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"results/vanilla_vgg.csv\"\n",
    "\n",
    "preds_vgg = vgg.model.predict_generator(get_batches(\"data/test\", batch_size=64, shuffle=False), \n",
    "                                        val_samples=len(os.listdir(\"data/test/unknown\")))\n",
    "\n",
    "pred_str = map(lambda x: \",\".join([\"%.10f\" % i for i in x]), preds_vgg.tolist())\n",
    "rows = [\",\".join([a,b]) + \"\\n\" for a,b in zip(files, pred_str)]\n",
    "with open(filename, \"a\") as f:\n",
    "    f.write(\"img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n\")\n",
    "    for row in rows:\n",
    "        f.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ft = finetune_resnet(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ft.load_weights(model_dir+\"resnet_2epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = res_ft.predict_generator(test_gen, val_samples=test_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ft_trunc.fit_generator(batches, \n",
    "                           batches.nb_sample, \n",
    "                           validation_data=val_batches, \n",
    "                           nb_val_samples = val_batches.nb_sample, \n",
    "                           nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ft.save_weights(model_dir+\"resnet_2epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_layer_inputs = res_ft_trunc.predict_generator(test_gen, val_samples=test_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_layer_inputs = intermediate_layer_output.predict_generator(batches, \n",
    "                                                                 batches.nb_sample)\n",
    "save_array(path+\"tuned_layer_inputs.bcolz\", tuned_layer_inputs)\n",
    "# tuned_layer_inputs = load_array(path+\"tuned_layer_inputs.bcolz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_layer_val_inputs = intermediate_layer_output.predict_generator(val_batches, \n",
    "                                                                     val_batches.nb_sample)\n",
    "save_array(path+\"tuned_layer_val_inputs.bcolz\", tuned_layer_val_inputs)\n",
    "# tuned_layer_val_inputs = load_array(path+\"tuned_layer_val_inputs.bcolz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ft_trunc = ResNet50()\n",
    "\n",
    "intermediate_layer_output = Model(input=res_ft_trunc.input, \n",
    "                                  output=res_ft_trunc.layers[-4].output)\n",
    "\n",
    "intermediate_layer_output.compile(optimizer=Adam(), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=intermediate_layer_output.output_shape[1:])\n",
    "mod = AveragePooling2D((7,7))(inputs)\n",
    "mod = Flatten()(mod)\n",
    "mod = Dense(10, name='wtf', activation='softmax', trainable=True)(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl = Model(input=inputs, output=mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in mdl.layers:\n",
    "#     if layer.name == 'dense_ft':\n",
    "#         layer.trainable = True\n",
    "#     else:\n",
    "#         layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20441 samples, validate on 1983 samples\n",
      "Epoch 1/1\n",
      "20441/20441 [==============================] - 3s - loss: 0.7531 - acc: 0.7889 - val_loss: 1.7397 - val_acc: 0.4826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f361a420f10>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "mdl.fit(tuned_layer_inputs, onehot(batches.classes), nb_epoch=1, \n",
    "        validation_data=(tuned_layer_val_inputs, onehot(val_batches.classes)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
