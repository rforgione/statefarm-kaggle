{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_utilities import *\n",
    "from keras_utilities.models.vgg16bn import Vgg16BN\n",
    "from keras_utilities.models.vgg16 import Vgg16\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "from numpy import array\n",
    "from IPython.display import FileLink\n",
    "from numpy.random import permutation\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import AveragePooling2D, Input, Dense, Flatten\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras_utilities import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod = True\n",
    "\n",
    "path = 'data/'\n",
    "    \n",
    "batch_size = 64\n",
    "\n",
    "model_dir = \"models/\"\n",
    "results_dir = \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20441 images belonging to 10 classes.\n",
      "Found 1983 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    zca_whitening=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.2,\n",
    "    fill_mode=\"nearest\"\n",
    "    \n",
    ")\n",
    "batches = get_batches(path+\"train\", batch_size=64)\n",
    "val_batches = get_batches(path+\"valid\", batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune_resnet(nb_classes, lr=.001):\n",
    "    rn = ResNet50(); rn.layers.pop(); rn.layers.pop(); rn.layers.pop()\n",
    "    \n",
    "    x = rn.layers[-1].output \n",
    "    mod = AveragePooling2D(name='avg_pool_ft', pool_size=(7,7))(x)\n",
    "    mod = Flatten(name='flatten_ft')(mod)\n",
    "    mod = Dense(nb_classes, name='dense_ft', activation='softmax')(mod)\n",
    "    \n",
    "    newmod = Model(input=rn.input, output=mod)\n",
    "    \n",
    "    for i in newmod.layers:\n",
    "        if i.name in ['dense_ft']:\n",
    "            i.trainable = True\n",
    "        else:\n",
    "            i.trainable = False\n",
    "    \n",
    "    opt = Adam(lr=lr)\n",
    "    newmod.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "    return newmod\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ft = finetune_resnet(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20441/20441 [==============================] - 276s - loss: 0.9300 - acc: 0.7654 - val_loss: 1.4869 - val_acc: 0.5023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef4de3ef10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ft.fit_generator(batches, \n",
    "                     batches.nb_sample, \n",
    "                     validation_data=val_batches, \n",
    "                     nb_val_samples = val_batches.nb_sample, \n",
    "                     nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ft.save_weights(model_dir+\"resnet_1epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20441/20441 [==============================] - 273s - loss: 0.3029 - acc: 0.9444 - val_loss: 1.3098 - val_acc: 0.5774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef49c378d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ft.fit_generator(batches, \n",
    "                     batches.nb_sample, \n",
    "                     validation_data=val_batches, \n",
    "                     nb_val_samples = val_batches.nb_sample, \n",
    "                     nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ft.save_weights(model_dir+\"resnet_2epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20441/20441 [==============================] - 274s - loss: 0.1928 - acc: 0.9669 - val_loss: 1.5236 - val_acc: 0.5204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef5a91ae90>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ft.fit_generator(batches, \n",
    "                     batches.nb_sample, \n",
    "                     validation_data=val_batches, \n",
    "                     nb_val_samples = val_batches.nb_sample, \n",
    "                     nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ft.save_weights(model_dir+\"resnet_3epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_prediction_file(filename, preds=None, model=None):\n",
    "    if not preds:\n",
    "        num_test_files = len(os.listdir(\"data/test/unknown\"))\n",
    "        test_gen = get_batches(\"data/test\", batch_size=128, shuffle=False)\n",
    "        preds = model.predict_generator(test_gen, val_samples=num_test_files)\n",
    "    elif not model and not preds:\n",
    "        raise ValueError(\"Must pass either preds or a model.\")\n",
    "        \n",
    "    files = os.listdir(\"data/test/unknown/\")\n",
    "        \n",
    "    pred_str = map(lambda x: \",\".join([\"%.10f\" % i for i in x]), preds.tolist())\n",
    "    rows = [\",\".join([a,b]) + \"\\n\" for a,b in zip(files, pred_str)]\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(\"img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n\")\n",
    "        for row in rows:\n",
    "            f.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_test_files = len(os.listdir(\"data/test/unknown\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = get_batches(\"data/test\", shuffle=False, class_mode=None)\n",
    "preds = res_ft.predict_generator(test_gen, val_samples=num_test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(\"data/test/unknown/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img_81601.jpg',\n",
       " 'img_14887.jpg',\n",
       " 'img_62885.jpg',\n",
       " 'img_45125.jpg',\n",
       " 'img_22633.jpg',\n",
       " 'img_45660.jpg',\n",
       " 'img_88962.jpg',\n",
       " 'img_92987.jpg',\n",
       " 'img_26932.jpg',\n",
       " 'img_57972.jpg']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"results/resnet_3layer_ft.csv\"\n",
    "pred_str = map(lambda x: \",\".join([\"%.10f\" % i for i in x]), preds.tolist())\n",
    "rows = [\",\".join([a,b]) + \"\\n\" for a,b in zip(files, pred_str)]\n",
    "with open(filename, \"a\") as f:\n",
    "    f.write(\"img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n\")\n",
    "    for row in rows:\n",
    "        f.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='results/resnet_3layer_ft.csv' target='_blank'>results/resnet_3layer_ft.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/statefarm-kaggle/results/resnet_3layer_ft.csv"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(\"results/resnet_3layer_ft.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "17456/17456 [==============================] - 550s - loss: 1.8595 - acc: 0.4785 - val_loss: 1.5956 - val_acc: 0.5076\n"
     ]
    }
   ],
   "source": [
    "# as a comparison, let's see what the vgg model spits out for val loss\n",
    "vgg = Vgg16()\n",
    "vgg.ft(10)\n",
    "vgg.fit(batches, val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"results/vanilla_vgg.csv\"\n",
    "\n",
    "preds_vgg = vgg.model.predict_generator(get_batches(\"data/test\", batch_size=64, shuffle=False), \n",
    "                                        val_samples=len(os.listdir(\"data/test/unknown\")))\n",
    "\n",
    "pred_str = map(lambda x: \",\".join([\"%.10f\" % i for i in x]), preds_vgg.tolist())\n",
    "rows = [\",\".join([a,b]) + \"\\n\" for a,b in zip(files, pred_str)]\n",
    "with open(filename, \"a\") as f:\n",
    "    f.write(\"img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n\")\n",
    "    for row in rows:\n",
    "        f.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ft.load_weights(model_dir+\"resnet_2epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = res_ft.predict_generator(test_gen, val_samples=test_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ft_trunc = finetune_resnet(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20441/20441 [==============================] - 273s - loss: 0.3029 - acc: 0.9444 - val_loss: 1.3098 - val_acc: 0.5774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef49c378d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ft.fit_generator(batches, \n",
    "                     batches.nb_sample, \n",
    "                     validation_data=val_batches, \n",
    "                     nb_val_samples = val_batches.nb_sample, \n",
    "                     nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_ft.save_weights(model_dir+\"resnet_2epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_layer_inputs = res_ft_trunc.predict_generator(test_gen, val_samples=test_gen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Merge can only be called on a list of tensors, not a single tensor. Received: <keras.layers.normalization.BatchNormalization object at 0x7fef5ad87b50>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-c5502bc5e6f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# pooling_layer.input = x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mwith_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooling_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mwith_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m             raise TypeError('Merge can only be called on a list of tensors, '\n\u001b[0;32m-> 1432\u001b[0;31m                             'not a single tensor. Received: ' + str(inputs))\n\u001b[0m\u001b[1;32m   1433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             raise RuntimeError('A Merge layer cannot be used more than once, '\n",
      "\u001b[0;31mTypeError\u001b[0m: Merge can only be called on a list of tensors, not a single tensor. Received: <keras.layers.normalization.BatchNormalization object at 0x7fef5ad87b50>"
     ]
    }
   ],
   "source": [
    "dense_layer = res_ft_trunc.layers.pop()\n",
    "flatten_layer = res_ft_trunc.layers.pop()\n",
    "pooling_layer = res_ft_trunc.layers.pop()\n",
    "\n",
    "x = res_ft_trunc.layers[-1].output\n",
    "\n",
    "pooling_layer.input = x\n",
    "with_pool = flatten_layer(pooling_layer)\n",
    "with_dense = dense_layer(with_pool)\n",
    "\n",
    "mdl = Model(input=res_ft_trunc.output, output=with_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl.predict(tuned_layer_inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
